{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YBIil0SoAxbO",
    "outputId": "d4088afa-ee28-49ac-9c3f-05b59ce47ada"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\yolov8_env\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\yolov8_env\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.1 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 2.2.6\n",
      "Torch version: 2.2.0+cu118\n",
      "GPU disponible: True\n",
      "Nom du GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "Test NumPy r√©ussi: [1 2 3]\n"
     ]
    }
   ],
   "source": [
    "# ‚öôÔ∏è Installer les d√©pendances\n",
    "!pip install numpy --upgrade --force-reinstall --quiet\n",
    "!pip install ultralytics --upgrade --quiet\n",
    "\n",
    "# üîç V√©rifier le GPU et les imports\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"GPU disponible:\", torch.cuda.is_available())\n",
    "print(\"Nom du GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"Aucun GPU\")\n",
    "\n",
    "# Test simple de NumPy\n",
    "test_array = np.array([1, 2, 3])\n",
    "print(\"Test NumPy r√©ussi:\", test_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I5XFdCp4DZhx",
    "outputId": "c72fd384-d877-4c7b-c5a8-f85b2c16e190"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 5. Entra√Æner le mod√®le\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kVZk7ReEFsUA",
    "outputId": "30b1d899-0631-4e28-c0d7-126ebb01a5ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fichier data.yaml trouv√©: C:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\data.yaml\n",
      "Chargement du mod√®le...\n",
      "D√©marrage de l'entra√Ænement...\n",
      "Ultralytics 8.3.167  Python-3.12.6 torch-2.2.0+cu118 CPU (11th Gen Intel Core(TM) i5-11400H 2.70GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=2, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=2, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-obb.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=test-run, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/train, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\train\\test-run, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=obb, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=15 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=2, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=2, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-obb.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=test-run, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/train, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\train\\test-run, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=obb, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=15 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    823174  ultralytics.nn.modules.head.OBB              [1, 1, [64, 128, 256]]        \n",
      " 22        [15, 18, 21]  1    823174  ultralytics.nn.modules.head.OBB              [1, 1, [64, 128, 256]]        \n",
      "YOLOv8n-obb summary: 144 layers, 3,082,710 parameters, 3,082,694 gradients, 8.4 GFLOPs\n",
      "\n",
      "Transferred 391/397 items from pretrained weights\n",
      "YOLOv8n-obb summary: 144 layers, 3,082,710 parameters, 3,082,694 gradients, 8.4 GFLOPs\n",
      "\n",
      "Transferred 391/397 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 583.6562.2 MB/s, size: 95.9 KB)\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 583.6562.2 MB/s, size: 95.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\train\\labels.cache... 675 images, 14 backgrounds, 9 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 675/675 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\train\\images\\107_jpg.rf.b8a5c85b41588d35f807660892343f2e.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.118262]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\train\\images\\19646406_web1_191204-VNE-package_jpg.rf.0f3bdf21d0e861c219718ece9c25d199.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.097081]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\train\\images\\33_jpg.rf.055df7a6b64d4f03eb6f47635b8ac028.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.1265163]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\train\\images\\40_jpeg.rf.9f7715101aa38046eccf45ceb21b3748.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.3359859]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\train\\images\\5images_jpg.rf.2d0d10806961614c23d93956f1d006e7.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.3891761]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\train\\images\\65_jpg.rf.94803a92d97a0b0fd4a7e43b12792c8a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0599736 1.0630281]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\train\\images\\767a0ec0-f325-4f52-a963-65439d112677_png.rf.5b5665cea9739fbaa51ab19ed0b88e30.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\train\\images\\WIN_20220412_23_17_25_Pro_jpg.rf.4940bd1e4657d05399b0df7459f904c8.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0530357]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\train\\images\\c27_jpg.rf.df2650ebac995a8e87d6266601389e6c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.2667089]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\train\\images\\c53_jpg.rf.d58988c250844a373b2f8d647012b9b2.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0185679]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 614.1349.3 MB/s, size: 213.6 KB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 614.1349.3 MB/s, size: 213.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\valid\\labels.cache... 192 images, 6 backgrounds, 1 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 192/192 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\valid\\images\\c120_jpg.rf.a0052a9d5acbd3742b0d3f66cb3a5054.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0712881]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\train\\test-run\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 63 weight(decay=0.0), 73 weight(decay=0.0005), 72 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\train\\test-run\u001b[0m\n",
      "Starting training for 2 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 63 weight(decay=0.0), 73 weight(decay=0.0005), 72 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\train\\test-run\u001b[0m\n",
      "Starting training for 2 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/333 [00:00<?, ?it/s]\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mD√©marrage de l\u001b[39m\u001b[33m'\u001b[39m\u001b[33mentra√Ænement...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Entra√Ænement avec param√®tres minimaux pour test\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Tr√®s peu d'epochs pour test\u001b[39;49;00m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m320\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Taille d'image r√©duite\u001b[39;49;00m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Batch tr√®s petit\u001b[39;49;00m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# CPU pour √©viter probl√®mes GPU\u001b[39;49;00m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mruns/train\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtest-run\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     27\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Entra√Ænement termin√©!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\yolov8_env\\Lib\\site-packages\\ultralytics\\engine\\model.py:799\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    796\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m    798\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer.hub_session = \u001b[38;5;28mself\u001b[39m.session  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m799\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m    801\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\yolov8_env\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:227\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    224\u001b[39m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\yolov8_env\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:388\u001b[39m, in \u001b[36mBaseTrainer._do_train\u001b[39m\u001b[34m(self, world_size)\u001b[39m\n\u001b[32m    386\u001b[39m     pbar = TQDM(\u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.train_loader), total=nb)\n\u001b[32m    387\u001b[39m \u001b[38;5;28mself\u001b[39m.tloss = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mon_train_batch_start\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Warmup\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\yolov8_env\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\yolov8_env\\Lib\\site-packages\\ultralytics\\data\\build.py:68\u001b[39m, in \u001b[36mInfiniteDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create an iterator that yields indefinitely from the underlying iterator.\"\"\"\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)):\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\yolov8_env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    629\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    630\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m631\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[32m    634\u001b[39m         \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[32m    635\u001b[39m         \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\yolov8_env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    673\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    674\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m675\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    676\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    677\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\yolov8_env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     49\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     53\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\yolov8_env\\Lib\\site-packages\\ultralytics\\data\\base.py:379\u001b[39m, in \u001b[36mBaseDataset.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m) -> Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    378\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return transformed label information for given index.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransforms\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_image_and_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\yolov8_env\\Lib\\site-packages\\ultralytics\\data\\augment.py:202\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    184\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[33;03mApply a series of transformations to input data.\u001b[39;00m\n\u001b[32m    186\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    199\u001b[39m \u001b[33;03m    >>> transformed_data = compose(input_data)\u001b[39;00m\n\u001b[32m    200\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     data = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\yolov8_env\\Lib\\site-packages\\ultralytics\\data\\augment.py:2192\u001b[39m, in \u001b[36mFormat.__call__\u001b[39m\u001b[34m(self, labels)\u001b[39m\n\u001b[32m   2188\u001b[39m         masks = torch.zeros(\n\u001b[32m   2189\u001b[39m             \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mask_overlap \u001b[38;5;28;01melse\u001b[39;00m nl, img.shape[\u001b[32m0\u001b[39m] // \u001b[38;5;28mself\u001b[39m.mask_ratio, img.shape[\u001b[32m1\u001b[39m] // \u001b[38;5;28mself\u001b[39m.mask_ratio\n\u001b[32m   2190\u001b[39m         )\n\u001b[32m   2191\u001b[39m     labels[\u001b[33m\"\u001b[39m\u001b[33mmasks\u001b[39m\u001b[33m\"\u001b[39m] = masks\n\u001b[32m-> \u001b[39m\u001b[32m2192\u001b[39m labels[\u001b[33m\"\u001b[39m\u001b[33mimg\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2193\u001b[39m labels[\u001b[33m\"\u001b[39m\u001b[33mcls\u001b[39m\u001b[33m\"\u001b[39m] = torch.from_numpy(\u001b[38;5;28mcls\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m nl \u001b[38;5;28;01melse\u001b[39;00m torch.zeros(nl)\n\u001b[32m   2194\u001b[39m labels[\u001b[33m\"\u001b[39m\u001b[33mbboxes\u001b[39m\u001b[33m\"\u001b[39m] = torch.from_numpy(instances.bboxes) \u001b[38;5;28;01mif\u001b[39;00m nl \u001b[38;5;28;01melse\u001b[39;00m torch.zeros((nl, \u001b[32m4\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\yolov8_env\\Lib\\site-packages\\ultralytics\\data\\augment.py:2243\u001b[39m, in \u001b[36mFormat._format_img\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m   2241\u001b[39m img = img.transpose(\u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m   2242\u001b[39m img = np.ascontiguousarray(img[::-\u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m random.uniform(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m) > \u001b[38;5;28mself\u001b[39m.bgr \u001b[38;5;129;01mand\u001b[39;00m img.shape[\u001b[32m0\u001b[39m] == \u001b[32m3\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m img)\n\u001b[32m-> \u001b[39m\u001b[32m2243\u001b[39m img = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[31mRuntimeError\u001b[39m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# V√©rifier que le fichier data.yaml existe\n",
    "data_path = r'C:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\data.yaml'\n",
    "if os.path.exists(data_path):\n",
    "    print(f\"‚úÖ Fichier data.yaml trouv√©: {data_path}\")\n",
    "else:\n",
    "    print(f\"‚ùå Fichier data.yaml non trouv√©: {data_path}\")\n",
    "\n",
    "# Charger le mod√®le YOLOv8 orient√© (OBB)\n",
    "print(\"Chargement du mod√®le...\")\n",
    "model = YOLO('yolov8n-obb.pt')\n",
    "\n",
    "print(\"D√©marrage de l'entra√Ænement...\")\n",
    "# Entra√Ænement avec param√®tres minimaux pour test\n",
    "results = model.train(\n",
    "    data=data_path,\n",
    "    epochs=2,  # Tr√®s peu d'epochs pour test\n",
    "    imgsz=320,  # Taille d'image r√©duite\n",
    "    batch=2,    # Batch tr√®s petit\n",
    "    device='cpu',  # CPU pour √©viter probl√®mes GPU\n",
    "    project='runs/train',\n",
    "    name='test-run',\n",
    "    exist_ok=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Entra√Ænement termin√©!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic pour comprendre le probl√®me NumPy\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"Python path:\", sys.path[:3])  # First 3 entries\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(\"‚úÖ NumPy import√© avec succ√®s\")\n",
    "    print(\"NumPy version:\", np.__version__)\n",
    "    print(\"NumPy path:\", np.__file__)\n",
    "    \n",
    "    # Test de base\n",
    "    arr = np.array([1, 2, 3])\n",
    "    print(\"Test array:\", arr)\n",
    "    \n",
    "    # Test torch.from_numpy\n",
    "    import torch\n",
    "    tensor = torch.from_numpy(arr)\n",
    "    print(\"‚úÖ torch.from_numpy fonctionne:\", tensor)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"‚ùå Erreur:\", e)\n",
    "    \n",
    "# Essayons de r√©installer avec pip\n",
    "import subprocess\n",
    "try:\n",
    "    result = subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"numpy\", \"--force-reinstall\"], \n",
    "                          capture_output=True, text=True)\n",
    "    print(\"R√©sultat r√©installation NumPy:\", result.returncode)\n",
    "    if result.stdout:\n",
    "        print(\"STDOUT:\", result.stdout[-200:])  # Last 200 chars\n",
    "    if result.stderr:\n",
    "        print(\"STDERR:\", result.stderr[-200:])  # Last 200 chars\n",
    "except Exception as e:\n",
    "    print(\"Erreur lors de la r√©installation:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üö´ Installation SANS Environnement Virtuel\n",
    "Installation directe dans le syst√®me Python principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Environnement virtuel d√©tect√©. Utilisation de l'installation syst√®me.\n",
      "Python executable: c:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\yolov8_env\\Scripts\\python.exe\n",
      "Python version: 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]\n",
      "\n",
      "üîΩ Installation des d√©pendances...\n",
      "Installation de numpy==1.24.3...\n",
      "‚ùå Erreur lors de l'installation de numpy==1.24.3: Command '['c:\\\\Users\\\\user\\\\Desktop\\\\Warehouse Parcel Classification Project\\\\model\\\\yolov8_env\\\\Scripts\\\\python.exe', '-m', 'pip', 'install', 'numpy==1.24.3', '--upgrade', '--user']' returned non-zero exit status 1.\n",
      "D√©tails: ERROR: Can not perform a '--user' install. User site-packages are not visible in this virtualenv.\n",
      "\n",
      "Installation de ultralytics...\n",
      "‚ùå Erreur lors de l'installation de ultralytics: Command '['c:\\\\Users\\\\user\\\\Desktop\\\\Warehouse Parcel Classification Project\\\\model\\\\yolov8_env\\\\Scripts\\\\python.exe', '-m', 'pip', 'install', 'ultralytics', '--upgrade', '--user']' returned non-zero exit status 1.\n",
      "D√©tails: ERROR: Can not perform a '--user' install. User site-packages are not visible in this virtualenv.\n",
      "\n",
      "Installation de torch...\n",
      "‚ùå Erreur lors de l'installation de torch: Command '['c:\\\\Users\\\\user\\\\Desktop\\\\Warehouse Parcel Classification Project\\\\model\\\\yolov8_env\\\\Scripts\\\\python.exe', '-m', 'pip', 'install', 'torch', '--upgrade', '--user']' returned non-zero exit status 1.\n",
      "D√©tails: ERROR: Can not perform a '--user' install. User site-packages are not visible in this virtualenv.\n",
      "\n",
      "Installation de torchvision...\n",
      "‚ùå Erreur lors de l'installation de torchvision: Command '['c:\\\\Users\\\\user\\\\Desktop\\\\Warehouse Parcel Classification Project\\\\model\\\\yolov8_env\\\\Scripts\\\\python.exe', '-m', 'pip', 'install', 'torchvision', '--upgrade', '--user']' returned non-zero exit status 1.\n",
      "D√©tails: ERROR: Can not perform a '--user' install. User site-packages are not visible in this virtualenv.\n",
      "\n",
      "Installation de opencv-python...\n",
      "‚ùå Erreur lors de l'installation de opencv-python: Command '['c:\\\\Users\\\\user\\\\Desktop\\\\Warehouse Parcel Classification Project\\\\model\\\\yolov8_env\\\\Scripts\\\\python.exe', '-m', 'pip', 'install', 'opencv-python', '--upgrade', '--user']' returned non-zero exit status 1.\n",
      "D√©tails: ERROR: Can not perform a '--user' install. User site-packages are not visible in this virtualenv.\n",
      "\n",
      "Installation de pillow...\n",
      "‚ùå Erreur lors de l'installation de pillow: Command '['c:\\\\Users\\\\user\\\\Desktop\\\\Warehouse Parcel Classification Project\\\\model\\\\yolov8_env\\\\Scripts\\\\python.exe', '-m', 'pip', 'install', 'pillow', '--upgrade', '--user']' returned non-zero exit status 1.\n",
      "D√©tails: ERROR: Can not perform a '--user' install. User site-packages are not visible in this virtualenv.\n",
      "\n",
      "Installation de pyyaml...\n",
      "‚ùå Erreur lors de l'installation de pyyaml: Command '['c:\\\\Users\\\\user\\\\Desktop\\\\Warehouse Parcel Classification Project\\\\model\\\\yolov8_env\\\\Scripts\\\\python.exe', '-m', 'pip', 'install', 'pyyaml', '--upgrade', '--user']' returned non-zero exit status 1.\n",
      "D√©tails: ERROR: Can not perform a '--user' install. User site-packages are not visible in this virtualenv.\n",
      "\n",
      "\n",
      "üîÑ Red√©marrage du kernel recommand√© apr√®s installation...\n"
     ]
    }
   ],
   "source": [
    "# üîß Installation directe sans environnement virtuel\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# D√©sactiver l'environnement virtuel s'il est actif\n",
    "if hasattr(sys, 'real_prefix') or (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix):\n",
    "    print(\"‚ö†Ô∏è Environnement virtuel d√©tect√©. Utilisation de l'installation syst√®me.\")\n",
    "else:\n",
    "    print(\"‚úÖ Utilisation de l'installation Python syst√®me\")\n",
    "\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Installation des packages directement avec pip syst√®me\n",
    "packages_to_install = [\n",
    "    \"numpy==1.24.3\",  # Version stable compatible\n",
    "    \"ultralytics\",\n",
    "    \"torch\",\n",
    "    \"torchvision\", \n",
    "    \"opencv-python\",\n",
    "    \"pillow\",\n",
    "    \"pyyaml\"\n",
    "]\n",
    "\n",
    "print(\"\\nüîΩ Installation des d√©pendances...\")\n",
    "for package in packages_to_install:\n",
    "    try:\n",
    "        print(f\"Installation de {package}...\")\n",
    "        result = subprocess.run([\n",
    "            sys.executable, \"-m\", \"pip\", \"install\", \n",
    "            package, \"--upgrade\", \"--user\"  # Installation utilisateur pour √©viter les permissions\n",
    "        ], capture_output=True, text=True, check=True)\n",
    "        print(f\"‚úÖ {package} install√© avec succ√®s\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"‚ùå Erreur lors de l'installation de {package}: {e}\")\n",
    "        if e.stderr:\n",
    "            print(f\"D√©tails: {e.stderr}\")\n",
    "\n",
    "print(\"\\nüîÑ Red√©marrage du kernel recommand√© apr√®s installation...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ NumPy 2.2.6 charg√© depuis: c:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\yolov8_env\\Lib\\site-packages\\numpy\\__init__.py\n",
      "‚úÖ Ultralytics import√© avec succ√®s\n",
      "‚úÖ PyTorch 2.2.0+cu118 - GPU: True\n",
      "‚úÖ Fichier data.yaml trouv√©\n",
      "\n",
      "üèãÔ∏è Test d'entra√Ænement minimal...\n",
      "Ultralytics 8.3.167  Python-3.12.6 torch-2.2.0+cu118 CPU (11th Gen Intel Core(TM) i5-11400H 2.70GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-obb.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=test-system, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=0, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=runs/train, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=runs\\train\\test-system, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=obb, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=15 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    823174  ultralytics.nn.modules.head.OBB              [1, 1, [64, 128, 256]]        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_24920\\1960301522.py:12: UserWarning: The NumPy module was reloaded (imported a second time). This can in some cases result in small but subtle issues and is discouraged.\n",
      "  import numpy as np\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n-obb summary: 144 layers, 3,082,710 parameters, 3,082,694 gradients, 8.4 GFLOPs\n",
      "\n",
      "Transferred 391/397 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 573.4534.3 MB/s, size: 95.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\train\\labels.cache... 675 images, 14 backgrounds, 9 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 675/675 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\train\\images\\107_jpg.rf.b8a5c85b41588d35f807660892343f2e.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.118262]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\train\\images\\19646406_web1_191204-VNE-package_jpg.rf.0f3bdf21d0e861c219718ece9c25d199.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.097081]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\train\\images\\33_jpg.rf.055df7a6b64d4f03eb6f47635b8ac028.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.1265163]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\train\\images\\40_jpeg.rf.9f7715101aa38046eccf45ceb21b3748.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.3359859]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\train\\images\\5images_jpg.rf.2d0d10806961614c23d93956f1d006e7.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.3891761]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\train\\images\\65_jpg.rf.94803a92d97a0b0fd4a7e43b12792c8a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0599736 1.0630281]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\train\\images\\767a0ec0-f325-4f52-a963-65439d112677_png.rf.5b5665cea9739fbaa51ab19ed0b88e30.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\train\\images\\WIN_20220412_23_17_25_Pro_jpg.rf.4940bd1e4657d05399b0df7459f904c8.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0530357]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\train\\images\\c27_jpg.rf.df2650ebac995a8e87d6266601389e6c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.2667089]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\train\\images\\c53_jpg.rf.d58988c250844a373b2f8d647012b9b2.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0185679]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 1261.2681.2 MB/s, size: 213.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\valid\\labels.cache... 192 images, 6 backgrounds, 1 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 192/192 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\valid\\images\\c120_jpg.rf.a0052a9d5acbd3742b0d3f66cb3a5054.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0712881]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 63 weight(decay=0.0), 73 weight(decay=0.0005), 72 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\train\\test-system\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/666 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Erreur: Numpy is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_24920\\1960301522.py\", line 33, in <module>\n",
      "    results = model.train(\n",
      "              ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\yolov8_env\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 799, in train\n",
      "    self.trainer.train()\n",
      "  File \"c:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\yolov8_env\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 227, in train\n",
      "    self._do_train(world_size)\n",
      "  File \"c:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\yolov8_env\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 388, in _do_train\n",
      "    for i, batch in pbar:\n",
      "                    ^^^^\n",
      "  File \"c:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\yolov8_env\\Lib\\site-packages\\tqdm\\std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "               ^^^^^^^^\n",
      "  File \"c:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\yolov8_env\\Lib\\site-packages\\ultralytics\\data\\build.py\", line 68, in __iter__\n",
      "    yield next(self.iterator)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\yolov8_env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 631, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\yolov8_env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 675, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\yolov8_env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "  File \"c:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\yolov8_env\\Lib\\site-packages\\ultralytics\\data\\base.py\", line 379, in __getitem__\n",
      "    return self.transforms(self.get_image_and_label(index))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\yolov8_env\\Lib\\site-packages\\ultralytics\\data\\augment.py\", line 202, in __call__\n",
      "    data = t(data)\n",
      "           ^^^^^^^\n",
      "  File \"c:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\yolov8_env\\Lib\\site-packages\\ultralytics\\data\\augment.py\", line 2192, in __call__\n",
      "    labels[\"img\"] = self._format_img(img)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\yolov8_env\\Lib\\site-packages\\ultralytics\\data\\augment.py\", line 2243, in _format_img\n",
      "    img = torch.from_numpy(img)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Numpy is not available\n"
     ]
    }
   ],
   "source": [
    "# üöÄ Test et Entra√Ænement apr√®s installation syst√®me\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Forcer le rechargement des modules\n",
    "if 'numpy' in sys.modules:\n",
    "    del sys.modules['numpy']\n",
    "if 'ultralytics' in sys.modules:\n",
    "    del sys.modules['ultralytics']\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(f\"‚úÖ NumPy {np.__version__} charg√© depuis: {np.__file__}\")\n",
    "    \n",
    "    from ultralytics import YOLO\n",
    "    print(\"‚úÖ Ultralytics import√© avec succ√®s\")\n",
    "    \n",
    "    import torch\n",
    "    print(f\"‚úÖ PyTorch {torch.__version__} - GPU: {torch.cuda.is_available()}\")\n",
    "    \n",
    "    # V√©rifier le fichier de configuration\n",
    "    data_path = r'C:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\wpd\\data.yaml'\n",
    "    if os.path.exists(data_path):\n",
    "        print(f\"‚úÖ Fichier data.yaml trouv√©\")\n",
    "    else:\n",
    "        print(f\"‚ùå Fichier data.yaml non trouv√©: {data_path}\")\n",
    "        \n",
    "    # Tester avec un mod√®le simple\n",
    "    print(\"\\nüèãÔ∏è Test d'entra√Ænement minimal...\")\n",
    "    model = YOLO('yolov8n-obb.pt')\n",
    "    \n",
    "    # Entra√Ænement de test tr√®s court\n",
    "    results = model.train(\n",
    "        data=data_path,\n",
    "        epochs=1,        # Juste 1 epoch pour test\n",
    "        imgsz=224,       # Taille tr√®s petite\n",
    "        batch=1,         # Batch minimum\n",
    "        device='cpu',    # CPU pour compatibilit√©\n",
    "        project='runs/train',\n",
    "        name='test-system',\n",
    "        exist_ok=True,\n",
    "        verbose=False,   # Moins de sorties\n",
    "        patience=0,      # Pas d'early stopping\n",
    "        save=False,      # Ne pas sauvegarder\n",
    "        plots=False      # Pas de graphiques\n",
    "    )\n",
    "    \n",
    "    print(\"üéâ Entra√Ænement test r√©ussi !\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üêç Alternative : Script Python Autonome\n",
    "Si le notebook pose encore des probl√®mes, utilisons un script Python ind√©pendant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Ex√©cution du script Python autonome\n",
    "# Ce script contourne les probl√®mes de notebook et utilise directement Python\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Chemin vers le script autonome\n",
    "script_path = r'C:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model\\train_standalone.py'\n",
    "\n",
    "print(f\"üìÑ Script cr√©√©: {script_path}\")\n",
    "print(\"üî• Lancement de l'entra√Ænement via script autonome...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Ex√©cuter le script avec Python syst√®me\n",
    "    result = subprocess.run([\n",
    "        sys.executable, script_path\n",
    "    ], \n",
    "    cwd=r'C:\\Users\\user\\Desktop\\Warehouse Parcel Classification Project\\model',\n",
    "    capture_output=False,  # Afficher la sortie en temps r√©el\n",
    "    text=True\n",
    "    )\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    if result.returncode == 0:\n",
    "        print(\"üéâ Script ex√©cut√© avec succ√®s !\")\n",
    "    else:\n",
    "        print(f\"‚ùå Le script s'est termin√© avec le code d'erreur: {result.returncode}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur lors de l'ex√©cution du script: {e}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "yolov8_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
